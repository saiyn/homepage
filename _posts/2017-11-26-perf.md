---
layout: post
title:  "调试技术之perf实战笔记"
date:   2017-11-26 15:15:54
categories: debug
excerpt: perf linux debug
---

* content
{:toc}

做音视频中间件开发的，不可避免的会遇到各种性能问题。不同于一般的bug，性能问题往往比较隐蔽，如果不借助于工具，只能是通过代码逻辑去揣测、去
猜想问题的原因，然后就是无休止的尝试。除了解决已经遇到到的性能问题，我们在设计实现新架构代码时，或者是去优化重构别人代码时，我们怎样去证明我们
的架构、我们的优化时合理高效的。所以掌握软件性能分析的技术和工具使用是称为高水平程序员的必备条件，更应该是称为架构师的前提条件。

<br />

# Perf 简介

<br />

# 背景知识与基础

<br />

不同于gdb这样的调试工具，如果你不掌握足够软件性能相关的基础背景知识，即使你熟悉每一个perf工具的命令，你依然发挥不了perf的作用。

<br />

## 性能相关的处理器硬件特性

<br />

**cache**

内存读写是很快的，但还是无法和处理器的指令执行速度相比。为了从内存中读取指令和数据，处理器需要等待，用处理器的时间来衡量，这种等待很漫长。
cache的读写速度非常快，能和处理器速度匹配。因此将常用的数据保存在cache中，处理器便无须等待，从而提高性能。但是，cache的容量一般很小，充分
利用cache是软件调优非常重要的部分。这里说的硬件cache和linux内核中实现的cache机制是不同的，不能混淆。关于linux下的buffer/cache知识，见[这篇文章](https://linux.cn/article-7310-1.html).

<br />

**pipeline**

提高性能最有效的方式之一就是并行。因此现代的处理器在硬件设计上都提供流水线（pipeline）技术来尽可能保证真正的指令并行。

处理器处理一条指令需要分多个步骤完成，比如先取指令，然后完成运算，最后将计算结果写回。在处理器内部，这就可以看作是一个三级流水线。
不同架构的处理器支持不同级数的流水线，比如arm9就支持了6级流水线，而intel架构的cpu一般支持三级流水线。流水线越多，表明一个时钟周期可以
同时处理的指令数越多。

大多数的pipeline主要由两部分组成，前端(front-end)和后端(back-end)。在x86架构的处理器中，pipeline的front-end负责从内存中获取指令，并将有序的汇编指令解码成机器原语(micro-operations)；back-end负责执行这些micro-operations。关于pipeline的front-end和back-end的详细内容可参见intel工程师的两篇
博文[front-end](https://software.intel.com/en-us/blogs/2011/11/22/pipeline-speak-learning-more-about-intel-microarchitecture-codename-sandy-bridge)、[back-end](https://software.intel.com/en-us/blogs/2011/12/01/pipeline-speak-part-2-the-second-part-of-the-sandy-bridge-pipeline)。下面引用其中核心的描述:

> So for X86-based processors, the front-end does two main things - fetch instructions(from where program binaries are stored in memory
> or the caching system), and decode them into micro-operations.As part of the fetching process, **the front-end must also predict the
> targets of branch instructions when they are encountered**, so that it knows where to grab the next instructions from.

perf工具的stat命令结果中的`stalled-cycles-frontend`和`stalled-cycles-backend`就是统计了pipeline的这两部分的工作状态。

上述的文章中提到了，在处理器内部，不同指令所需要的处理器步骤和时钟周期是不同的，如果严格按照程序的执行顺序执行，那么就无法充分利用处理器的流水线。因此指令有可能被乱序执行。


上述并行技术对所执行的指令有一个基本要求，即相邻的指令没有依赖关系。假如某条指令需要依赖前面的一条指令的执行结果数据，那么这些技术就
无法被利用。因此，在使用perf工具的stat命令时，有一个非常重要的统计指标就是IPC(instructions per cycle)，一般这个值大于1.0时，才表示程序
的执行效率是健康的。大神Brendan Gregg关于IPC的解释如下:

> IPC is a commonly examined metric, either IPC or its invert, CPI. Higher IPC values mean higher instrucion throughput,
> and lower values indicated more stall cycles. I'd generally interpert high IPC values(eg, over 1.0) as good, indicating 
> optimal processing of work. However, I'd want to double check what the instructions are, in case this is due to s spin
> loop: a high rate of instructions, but a low rate of actual work completed.

<br />

**分支预测**


分支指令对软件性能有比较大的影响。尤其是当处理器采用流水线设计之后，假设流水线有三级，当前进入流水的第一条指令为分支指令。假设处理器顺序读取指令，那么如果分支的结果是跳转到其他指令，那么被处理器流水线预取的后续两条指令都将被放弃，从而影响性能。为此，很多处理器都提高分支预测功能，根据一条指令的历史执行记录进行预测，读取最可能的下一条指令，而非顺序读取指令。

分支预测对软件结构有一些要求，对于重复性的分支指令序列，分支预测硬件得到较好的预测结果，而对于类似switch case一类的程序结构，则往往无法得到理想的预测结果。关于linux中分支预测的运用请看[这篇文章](http://saiyn.github.io/homepage/2016/08/07/C/)中的相关章节。

<br />

**PMU**

上面介绍的几种处理器硬件特性对软件的性能有很大的影响，然而依赖时钟进行定期采样的profiler模式无法揭示程序对这些处理器硬件特性的真实使用情况。
处理器厂商针对这种情况，在硬件中加入了PMU(performace monitor unit)单元。

PMU允许软件针对某种硬件事件设置counter,此后处理器便开始统计该事件的发生次数，当发生的次数超过counter内设置的值后，便产生中断。比如cashe miss达到
某个值后，PMU便能产生相应的中断。捕获这些中断，便可以考察程序对这些硬件特性的利用效率了。

<br />

# perf实战

<br />

## Dynamic Tracing

<br />

内核代码的调试不像应用程序那么方便，大部分情况下我们只是通过在内核代码中添加打印来调试，效率非常的低下。部署使用KGDB也比较麻烦，本节介绍如何使用内核
自带的调试工具perf中的probe命令，实现部分动态追踪调试的功能。








