---
layout: post
title:  "ffmpeg笔记"
date:   2017-03-20 15:15:54
categories: ffmpeg
excerpt: ffmpeg linux note
---

* content
{:toc}


近一两年内开源项目中对我工作影响和帮助最大的非ffmpeg莫属，ffmpeg的强大以及被使用的普遍性令人惊讶。每次阅读ffmpeg的源代码都感觉收获颇多，经常将从ffmpeg里面吸收的代码技巧和音视频算法用于公司的实际项目中，解决实际问题的同时也提示自己的代码质量。感谢开源的精神与力量。


---

## ffmpeg硬解(vaapi-decode)流程分析

<br />

本章节主要关注的是ffmpeg中硬件解码h264的流程分析，而其中的解码算法细节实现暂不展开。已故雷神雷宵铧的博客中关于ffmpeg的h264解码已经比较详细的分析，
但是不同版本的ffmpeg解码部分函数实现差别很大，其博客中的一些函数分析已经过时，而且没有涉及硬件解码的情况。但是雷神文章中对于ffmpeg解码的总体流程分析还是很有指导意义的，对雷神
的钻研精神表示敬意。

本文都是基于较新的v3.3.3版本的ffmpeg进行代码分析。

ffmpeg中使用AVCodec结构体描述解码器对象，其中h264解码器为实现在src/libavcodec/h264dec.c中的ff_h264_decoder实例。无论是软解还是硬解，解码流程的入口都是avcodec_decodec_video2()这个API接口调用ff_h264_decoder中注册的h264_decode_frame()方法。

	/*libavcodec/h264dec.c*/
	static int h264_decode_frame(AVCodecContext *avctx, void *data, int *get_frame, AVPacket *avpkt)
	{
		...
		
		/**
		 * end of stream, output what is still in the buffers
		 */
		if(buf_size == 0)
			return send_next_delayed_frame(h, pict, got_frame, 0);
			
		...
		
		decode_nal_units(h, buf, buf_size);//[0]
		 
		...
		
		ff_h264_field_end(h, &h->slice_ctx[0], 0);//[1]
		
		/**
		 * wait for second field.
		 */
	
		if(h->next_output_pic)
			finalize_frame(h, pict, h->next_output_pic, got_frame);//[2]
			
		...	
	}

上面的主要处理流程是，[0]处进行码流分析，如果是软解就接着进行解码工作，如果是硬件就只设置解码器的参数，然后在[1]处进行实际的硬解码，[2]处是控制
POC，决定输出哪一帧。

	/*libavcodec/h264dec.c*/
	static int decodec_nal_units(H264Context *h, const uint8_t *buf, int buf_size)
	{
		...
		
		/**
		 * 拆分协议信息。
		 */
		ff_h245_packet_split(&h->pkt, buf, buf_size, avctx, ...);
		
		...
		
		/**
		 * 对上面拆分出的各个NALU进行逐个解析。
		 */
		for(i = 0; i < h->pkt.nb_nals; i++)
		{
			...
			
			switch(nal->type){
				case H264_NAL_IDR_SLICE:
				case H264_NAL_SLICE_SCALABLE:
				case H264_NAL_SLICE:
					h->has_slice = 1;
					
					ff_h264_queue_decode_slice(h, nal);//[0]
					
					if(h->current_slice == 1){
						...
						
						/**
						 * avctx中的hwaccel句柄如果有效，说明开启的是vaapi流程。
						 */
						if(h->avctx->hwaccel)
							h->avctx->hwaccel->start_frame(...);	
							
						...	
					}
					
					max_slice_ctx = avctx->hwaccel ? 1 : h->nb_silce_ctx;
					if(h->nb_slice_ctx_queued == max_slice_ctx){
						if(h->avctx->hwaccel){
							/**
							 * 这里只是进行硬件解码器的参数设置。
							 */
							avctx->hwaccel->decoded_slice(...);
							h->nb_slice_ctx_queued = 0;
						}else{
							...
							/**
							 * 如果是软解，调用
							 * ff_h264_execute_decode_slice()进行解码。
							 */
						}
					}
					
					break;
					
				case H264_NAL_SEI:
					/**
					 * 解析SEI信息。
					 */
					 ff_h264_sei_decode(&h->sei, &nal->gb, &h->ps, avctx);
					
				case H264_NAL_SPS:
					/**
					 * 解析sps信息。
					 */
					ff_h264_decode_seq_parameter_set(&tmp_gb, avctx, &h->ps, 0);
					...
				break;
				
				case H264_NAL_PPS:
					/**
					 * 解析PPS信息。
					 */
					ff_h264_decode_picture_parameter_set(...);
					...
				break;
				
				case xxx:
					...
				
			}
			
			/**
			 * error handle
			 */
			 ...
		}
	}

上面处理中，主要分成两个阶段，一个是解析非slice类型的NALU，包括PPS,SPS,SEI等，另外一个就是解析slice。而解析非slice类型NALU也是
为了解析slice服务的。上面[0]处就是解析slice，实现比较复杂，涉及到帧解码、场解码的兼容；根据不同POC类型计算POC值等等。

当slice信息也解析完成后，最终解析码流的所需要的所有信息已经拿到了，下面就是开启硬件解码器(*hwaccel->start_frame()*)，并将解析的信息按需传入
(*hwaccel->decoded_slice()*)。

下面先分析[0]处的ff_h264_queue_decode_slice()函数实现。

	int ff_h264_queue_decode_slice(H264Context *h, H2645NAL *nal)
	{
		
	
	}


---

## ffmpeg硬编(vaapi-encode)流程分析

<br />

---

## 解决ffmpeg解码首帧I帧不输出问题

<br />




<br />

---

## ffserver

<br />

ffserver is a multimedia streaming server for live broadcasts. With it, you can streamover HTTP,RTP and RSTP.

![ffserver](https://www.alkannoide.com/wp-content/uploads/2013/07/ffserver_map.png)

<br />

### 配置文件

<br />

研究ffserver得从配置文件开始，doc/ffserver.conf 是配置文件的模板。ffserver　reads a configuration file containing global options and settings for each stream and feed.

主要的语法规则:
The configuration file consists of global options and dedicated sections, which must be introduced by "<SECTION_NAME ARGS>" on a separate line and must be terminated by a line in the form "</SECTION_NAME>". ARGS is a optional.

下面分别说明配置文件中的各个模块

<br />

**Feed section**

Feed 就是输入源的意思，这个配置模块就是告诉ffserver关于输入源的一些信息。比如这个输入源的名字，这个源数据量的大小，以及哪些地址的客户端可以接受这个源数据。You must use 'ffmpeg' to send a live feed to ffserver. In this example, you can type:ffmpeg http://localhost:8090/feed1.ffm. 第一种方式就是使用ffmpeg程序执行命令产生实时的数据流，比如执行`ffmpeg -i INPUTFILE http://localhost:8090/feed1.ffm`,其中`feed1.ffm`就是这个源的名字。ffserver can also do time shifting.It means that it can stream any previously recorded live stream.You must specify a path where the feed is stored on disk.You alsa specify the maximum size of the feed,where 0 means unlimited.第二种就是从硬盘中加载已经录制好的源，当然格式必须是.ffm的。这样我们可以写个feed配置块。

![feed1](http://omp8s6jms.bkt.clouddn.com/image/git/feed1.png)

<br />

**Stream section**

在说明stream配置模块前，先说明一下feed和stream的关系。A "live-stream" or "sream" is a resource published by ffserver,and made accessible through the HTTP protocol to cliens.	A stream can be connected to a feed, or to a file. In the first case, the published stream is forwarded from the corresponding feed generated by a running instance of ffpmeg.也就是说，stream是对feed的封装。Multiple streams can be connected to the same feed.下面是一个实例图:

![graph](http://omp8s6jms.bkt.clouddn.com/image/git/graph.png)

<br />

stream配置中主要包含三块内容，这个stream是对接的哪个feed；stream的格式;stream中的音视频码流参数。下面是ffserver目前支持的格式:

mpeg	|MPEG-1 multiplexed video and audio
mpegvideo	|only MPEG-1 video
mp2	|MPEG-2 audio(use AudioCodec to select layer 2 and 3 codec)
ogg	|ogg format(vorbis audio codec)
rm	|RealNetworks-compatible stream.Multiplexed audio and video.
ra	|RealNetworks-compatible stream.Audio only.
mpjpeg	|Multipart JPEG 
jpeg	|Generate a single JPEG image
mjpeg	|Generate a M_JPEG stream
asf	|ASF compatible streaming(Windows Media Player format)
swf	|Macromedia Flash compatible stream
avi	|AVI format(MPEG-4 video, MPEG audio sound)

<br />

下面是一个配置实例:

![stream2](http://omp8s6jms.bkt.clouddn.com/image/git/stream2.png)

<br />

最后，还要一个special stream.用来在网页上监控ffserver的状态信息。

![stream3](http://omp8s6jms.bkt.clouddn.com/image/git/stat.png)

<br />

This page will help us to moniter the server.This page is call with this url:http://localhost:8090/stat.html and you will get this page.执行如下的命令:

![ffser_cmd](http://omp8s6jms.bkt.clouddn.com/image/git/ffse_ffp.png)

<br />

得到如下的状态：

![status](http://omp8s6jms.bkt.clouddn.com/image/git/ffserver.png)

<br />

从上图可以看到我们已经成功的创建了一个名为`test1.mpg`的流，在另外一个终端上执行`ffplay http://localhost:8090/test1.mpg`或者执行`cvlc http://localhost:8090/test1.mpg`都可以进行拉流播放。



---


















